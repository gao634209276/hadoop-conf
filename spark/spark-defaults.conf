#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
spark.eventLog.enabled           true
spark.eventLog.dir               hdfs:///user/spark/eventLog/applicationHistory
spark.history.fs.logDirectory    hdfs:///user/spark/eventLog/applicationHistory
spark.serializer                  org.apache.spark.serializer.KryoSerializer

spark.sql.warehouse.dir          hdfs://ark:8020/user/sinova/hive/warehouse
spark.sql.hive.metastore.version 0.14.0
spark.sql.hive.metastore.jars    /app/sinova/hive-0.14.0/lib/*

spark.driver.cores                 2
spark.driver.memory                8g
spark.driver.maxResultSize         2g
spark.driver.extraJavaOptions      -XX:MaxDirectMemorySize=1024M -XX:MaxPermSize=256M
spark.executor.cores               1
spark.executor.memory              8g
# spark.executor.instances         40
spark.executor.extraJavaOptions    -XX:MaxDirectMemorySize=1024M -XX:MaxPermSize=256M -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps

# spark.driver.extraClassPath      /app/spark-2.0.2/jars/hive-hbase-handler-0.14.0.jar:/app/spark-2.0.2/jars/hbase-client-0.98.9-hadoop2.jar:/app/spark-2.0.2/jars/hbase-protocol-0.98.9-hadoop2.jar:/app/spark-2.0.2/jars/hbase-common-0.98.9-hadoop2.jar:/app/spark-2.0.2/jars/hbase-server-0.98.9-hadoop2.jar:/app/spark-2.0.2/jars/htrace-core-2.04.jar:/app/spark-2.0.2/jars/guava-12.0.1.jar:/app/spark-2.0.2/jars/protobuf-java-2.5.0.jar




#spark yarn
spark.master                       yarn
spark.yarn.archive                 hdfs://ark:8020/user/sinova/spark/archive/spark_libs.zip
spark.yarn.stagingDir              hdfs://ark:8020/user/sinova/spark/staging
spark.yarn.historyServer.address   ark:18080
spark.yarn.am.cores                2
spark.yarn.am.memory               8g
spark.yarn.am.memoryOverhead       2g
spark.yarn.am.extraJavaOptions     -XX:MaxDirectMemorySize=1536M -XX:MaxPermSize=256M
spark.yarn.am.waitTime             100s
spark.yarn.driver.memoryOverhead   10g
spark.yarn.executor.memoryOverhead 8g 
spark.yarn.submit.file.replication 1
spark.yarn.preserve.staging.files  false
spark.yarn.scheduler.heartbeat.interval-ms 60000
## half  yarn.am.liveness-monitor.expiry-interval-ms default 10min
## spark.yarn.scheduler.initial-allocation.interval 200ms
## spark.yarn.max.executor.failures 6
spark.executor.heartbeatInterval   60




# spark yarn external shuffle Service
spark.shuffle.service.enabled      true
spark.shuffle.service.port         7337
# spark.dynamicAllocation.enabled true 
# spark.dynamicAllocation.executorIdleTimeout 60s
# spark.dynamicAllocation.maxExecutors  10
# spark.dynamicAllocation.minExecutors  1
# spark.dynamicAllocation.sustainedSchedulerBacklogTimeout 5s
# spark.dynamicAllocation.schedulerBacklogTimeout 1s
# spark.dynamicAllocation.initialExecutors 2
