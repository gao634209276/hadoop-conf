#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
spark.master                     spark://hadoop:7077
spark.eventLog.enabled           true
spark.eventLog.dir               hdfs:///user/spark/eventLog/applicationHistory
# spark.serializer               org.apache.spark.serializer.KryoSerializer
#spark.driver.memory              2g






#spark.driver.extraClassPath     /opt/sinova/hive-0.14.0/lib/hive-hbase-handler-0.14.0.jar:/opt/sinova/hbase-0.98.9/lib/hbase-client-0.98.9-hadoop2.jar:/opt/sinova/hbase-0.98.9/lib/hbase-protocol-0.98.9-hadoop2.jar:/opt/sinova/hbase-0.98.9/lib/hbase-common-0.98.9-hadoop2.jar:/opt/sinova/hbase-0.98.9/lib/hbase-server-0.98.9-hadoop2.jar:/opt/sinova/hbase-0.98.9/lib/htrace-core-2.04.jar:/opt/sinova/hbase-0.98.9/lib/guava-12.0.1.jar:/opt/sinova/hbase-0.98.9/lib/protobuf-java-2.5.0.jar
# spark on yarn
# spark.master                     yarn
#spark.yarn.am.memory             1g
#spark.yarn.am.cores              1
#spark.yarn.am.waitTime           100s

# spark.yarn.submit.file.replication 3
#spark.yarn.stagingDir             hdfs:///user/spark/staging
# spark.yarn.preserve.staging.files false
# spark.yarn.scheduler.heartbeat.interval-ms 3000
## half  yarn.am.liveness-monitor.expiry-interval-ms
# spark.yarn.scheduler.initial-allocation.interval 200ms
# spark.yarn.max.executor.failures 6
#spark.yarn.historyServer.address hadoop:18080
#spark.executor.cores             1
# spark.executor.instances         2
# spark.yarn.executor.memoryOverhead 500
# spark.yarn.driver.memoryOverhead 500
# spark.yarn.am.memoryOverhead     500

#spark.yarn.queue                 default
#spark.yarn.jars                  hdfs://hadoop:8020/user/spark/jar/*

# spark.yarn.archive               hdfs:///tmp/spark/archive/spark-assembly-hadoop2.5.2.zip
# spark.yarn.access.namenodes      hdfs://yh-hdp:8020
## hdfs://bj-ecs-jm429-i-e2-1-bl460c-10-null-10:8020,hdfs://bj-ecs-jm429-I-e2-1-bl460c-9-null-9:8020
# spark.yarn.containerLauncherMaxThreads 25


spark.sql.hive.metastore.jars  /opt/sinova/hive-0.14.0/lib/*
spark.sql.warehouse.dir        hdfs:///user/hive/warehouse
spark.serializer                org.apache.spark.serializer.KryoSerializer
spark.memory.fraction           0.75
spark.locality.wait             5s
spark.locality.wait.process     5s
spark.locality.wait.node        3s
spark.locality.wait.rack        2s
spark.reducer.maxSizeInFlight   64m
spark.shuffle.file.buffer       32k
spark.shuffle.io.retryWait      10s
## spark.shuffle.manager        tungsten-sort
## deprecated
# spark.memory.offHeap.enabled     true
# spark.memory.fraction            0.6
# spark.memory.storageFraction     0.5

